## 1. Тестирование с wrk2

**Порядок действий**:
1. Запускаю сервер через `./gradlew run`
2. Запускаю wrk и с выбранным rps.
3. Выключаю сервер.
3. Смотрю перцентиль.
4. Примерно понимаю на каком этапе стало снижаться latency и сужаю область поиска точки разладки, условный бинпоиск.
5. Возвращаюсь на этап 1 пока не найду точку

### 1.1 Get

**Команда для запуска:**
```
 wrk -d 30 -t 1 -c 1 -R 50000 -L -s ./src/main/java/ru/vk/itmo/test/kovalchukvladislav/resources/lua/get.lua http://localhost:8080 >> src/main/java/ru/vk/itmo/test/kovalchukvladislav/resources/wrk/get50000
```


**Итерации:**
1. Запуск с 50000 rps. latency почти сразу начинает проседать, где-то с 20-30 персентиля. График шумный, не понятно.  
[get50000](wrk/get50000)  
[get50000.png](wrk/get50000.png)
2. Запуск с 35000 rps. График стал менее шумным, но все еще не понятным. Так же, где то с +- 30% перцентиля все растет.  
[get35000](wrk/get35000)  
[get35000.png](wrk/get35000.png)  
3. Запуск с 20000 rps. Намного лучше, рост идет после 92 перцентиля.  
   [get20000](wrk/get20000)  
   [get20000.png](wrk/get20000.png)
4. Запуск с 17000 rps. Ожидалось, что рост пойдет позже 92 перцентиля, но он примерно там же: 85-90.  
   [get17000](wrk/get17000)  
   [get17000.png](wrk/get17000.png)
5. Запуск с 15000 rps. Идеально. Высокие значения на 99.3+ перцентиле. Сделал еще несколько итераций, все так и оставалось.  
   [get15000](wrk/get15000)  
   [get15000.png](wrk/get15000.png)

**Вывод**:
Наш сервер уверенно выдерживает 15к get запросов в секунду. Это и есть точка разладки.
Если быть точнее, она наверняка находится между 15000 и 17000 запросами, но думаю там будет слишком шумно.
Лучше взять с небольшим запасом для уверенности.  
Тут происходит упор в CPU, так как диск мы не нагружаем и ничего не пишем.
Либо это межсетевое (в данном случае локальное) взаимодействие.

### 1.2 Put

**Команда для запуска:**
```
wrk -d 30 -t 1 -c 1 -R 50000 -L -s ./src/main/java/ru/vk/itmo/test/kovalchukvladislav/resources/lua/put.lua http://localhost:8080 >> src/main/java/ru/vk/itmo/test/kovalchukvladislav/resources/wrk/put50000
```

1. Запуск с 50000 rps. У 50000 put намного позже растет latency, чем у 50000 get. Примерно 60-80 перцентиль.
[put50000](wrk/put50000)  
[put50000.png](wrk/put50000.png)

2. Запуск с 35000 rps. График менее шумный, двигаемся к +- 75 перцентилю.  
[put35000](wrk/put35000)  
[put35000.png](wrk/put35000.png)

3. Запуск с 25000 rps. Идеально! Рост на 99.7 перцентиле, можно попробовать увеличить.  
[put25000](wrk/put25000)  
[put25000.png](wrk/put25000.png)

4. Запуск с 30000 rps. Не идеально. Рост на 96.8 перцентиле.
   [put30000](wrk/put30000)  
   [put30000.png](wrk/put30000.png)

5. Запуск с 26000 rps. Рост на 98.9 перцентиле.
   [put26000](wrk/put26000)  
   [put26000.png](wrk/put26000.png)

**Вывод**:
   Наш сервер уверенно выдерживает 25к put запросов в секунду. Это и есть точка разладки.  
   Почему именно такое число? Тут происходит упор в диск и фоновый flush.

   Примерно посчитаем размер всех данных. Я пишу пару `k(number):v(number)`. Посчитаем длину в байтах строки `k25000`.  
   Это 6 байт. Еще 6 байт на значение. Еще по 8 байтов на 2 long'а для их длины. В сумме примерно 20 байтов.
   20 байтов умножить на 25к запросов в секунду = 500000 байт = 500Кб. То есть каждые 2 секунды мы делаем flush()

   С этим наш сервер без проблем справляется и поддерживает примерно тот же latency.
   Но если увеличить rps, flush будет работать чаще, и latency начинает сильно отклоняться.
   
   Можно увеличить flush threshold, и тогда flush() будет происходить реже.
   Но и это делать надо аккуратно: как мы помним из предыдущего пункта, на 15000 get запросов мы уже упираемся в CPU (или сеть).
   Поиск оптимального flush threshold зависит, в том числе от производительности CPU и сколько мы готовы хранить в памяти.
## 2. Профилирование с async-profiler